{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bengluru flat price estimation\n",
        "\n"
      ],
      "metadata": {
        "id": "unrInOqa7bKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "#adding data set to the code:\n",
        "raw_data=pd.read_csv('/content/Bengaluru_House_Data.csv')\n",
        "raw_data.head()\n",
        "# raw_data.describe()\n",
        "data1=raw_data.drop(['area_type','society','balcony','availability'],axis=1)\n",
        "data1.head()\n",
        "\n",
        "#seeing all null or empty values:\n",
        "data1.isnull().sum()\n",
        "#since these are very less in number so we can take the risk to remove them:\n",
        "data2=data1.dropna()\n",
        "data2.isnull().sum()\n",
        "#now all empty rows are removed\n",
        "data2.head()\n",
        "#as we can see in the data frame there are different notations in size to make it general and in int type so we can easily process it:\n",
        "data2['size'].unique()\n",
        "#lets make a new column called bhk:\n",
        "\n",
        "data2['BHK']=data2['size'].apply(lambda x: int(x.split(' ')[0]))\n",
        "#creating a checkpoint\n",
        "\n",
        "data3=data2.copy()\n",
        "data3.head()\n",
        "data3['BHK'].unique()\n",
        "data3.head()\n",
        "\n",
        "#analyzing total_sqft column:\n",
        "data3.total_sqft.unique()\n",
        "#as we can see there is  a range we have to convert them into a number so they can we used in analyses:\n",
        "#checking every row:\n",
        "def is_float(x):\n",
        "  try:\n",
        "    float(x)\n",
        "  except:\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "data3[~data3['total_sqft'].apply(is_float)].head()\n",
        "print(data3.head())\n",
        "#coverting all these to mean of there range:\n",
        "def converting_sqft_to_num(x):\n",
        "  tokens=x.split(\"-\")\n",
        "  if len(tokens)==2:\n",
        "    return (float(tokens[0])+float(tokens[1]))/2\n",
        "  try:\n",
        "    return float(x)\n",
        "  except:\n",
        "    return None\n",
        "\n",
        "data3['total_sqft']=data3['total_sqft'].apply(converting_sqft_to_num)\n",
        "data4=data3.copy()\n",
        "data4.head()\n",
        "\n",
        "data4['Price_per_sqft']=data4['price']*100000/data4['total_sqft']\n",
        "data4.head()\n",
        "\n",
        "data4.location=data4.location.apply(lambda x:x.strip())\n",
        "location_stats=data4.groupby('location')['location'].agg('count').sort_values(ascending=False)\n",
        "location_stats\n",
        "\n",
        "location_stats_less_than_10=location_stats[location_stats<=10]\n",
        "location_stats_less_than_10\n",
        "\n",
        "data4.location=data4.location.apply(lambda x:'other' if x in location_stats_less_than_10 else x)\n",
        "data4.head()\n",
        "len(data4['location'].unique())\n",
        "\n",
        "#dealing with outliers:\n",
        "#total sqrft per bhk should be more than 300\n",
        "data4[data4.total_sqft/data4.BHK<300].head()\n",
        "data5=data4[~(data4.total_sqft/data4.BHK<300)]\n",
        "# print(data5.shape)\n",
        "#removing the outlires of pps according to mean and std:\n",
        "def remove_pps_outliers(data5):\n",
        "  data5_out=pd.DataFrame()\n",
        "  for key,subdata5 in data5.groupby('location'):\n",
        "    m=np.mean(subdata5.Price_per_sqft)\n",
        "    st=np.std(subdata5.Price_per_sqft)\n",
        "    reduced_data5=subdata5[(subdata5.Price_per_sqft>(m-st))&(subdata5.Price_per_sqft<=(m+st))]\n",
        "    data5_out=pd.concat([data5_out,reduced_data5],ignore_index=True)\n",
        "  return data5_out\n",
        "\n",
        "data6=remove_pps_outliers(data5)\n",
        "data6.head()\n",
        "print(data6.shape)\n",
        "\n",
        "#since many less bhk apartments st the same location  are having price more than high bhk apartments in the data set we have to remove thoose rows so applying the fun:\n",
        "def remove_bhk_outliers(df):\n",
        "  exclude_indices=np.array([])\n",
        "  for location,location_df in df.groupby('location'):\n",
        "     bhk_stats={}\n",
        "     for bhk,bhk_df in location_df.groupby('BHK'):\n",
        "      bhk_stats[bhk]={\n",
        "          'mean':np.mean(bhk_df.Price_per_sqft),\n",
        "          'std':np.std(bhk_df.Price_per_sqft),\n",
        "          'count':bhk_df.shape[0]\n",
        "      }\n",
        "     for bhk,bhk_df in location_df.groupby('BHK'):\n",
        "      stats=bhk_stats.get(bhk-1)\n",
        "      if stats and stats['count']>5:\n",
        "        exclude_indices=np.append(exclude_indices,bhk_df[bhk_df.Price_per_sqft<(stats['mean'])].index.values)\n",
        "        # print('hello')\n",
        "        # print(len(exclude_indices))\n",
        "\n",
        "  return df.drop(exclude_indices,axis='index')\n",
        "\n",
        "data7=remove_bhk_outliers(data6)\n",
        "print(data7.shape)\n",
        "\n",
        "#removing those outlires in which number of bathroom are greater than number of bedrooms\n",
        "data8=data7[data7.bath<data7.BHK+2]\n",
        "print(data8.shape)\n",
        "#since are are not majorily outlires of such kind here therfore can be used with this dataframe\n",
        "\n",
        "#modelling:\n",
        "#since location are in string format we have to covert them in numeric using one hot encoding methode:\n",
        "dummies=pd.get_dummies(data8.location).applymap(lambda x: 1 if x==True else 0)\n",
        "data9=pd.concat([data8,dummies],axis=1)\n",
        "data9.head()\n",
        "#now we will be dropping others column bcz its understood that if all others are zero than others will be 1 and also the location column bcz now its of no use also removing those columns which we added and were not given in initial dataset;\n",
        "\n",
        "data10=data9.drop(['other','location','size','Price_per_sqft'],axis=1)\n",
        "data10\n",
        "print(data10.shape)\n",
        "\n",
        "\n",
        "#dividing our data set into training and testing dataset:\n",
        "x=data10.drop('price',axis=1)\n",
        "y=data10['price']\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=10)\n",
        "\n",
        "#now applying linear regression model:\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lr_clf=LinearRegression()\n",
        "lr_clf.fit(x_train,y_train)\n",
        "print(lr_clf.score(x_test,y_test))\n",
        "\n",
        "\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv=ShuffleSplit(n_splits=5,test_size=0.2,random_state=0)\n",
        "cross_val_score(LinearRegression(),x,y,cv=cv)\n",
        "\n",
        "#applying Gridsearchcv to find the best algorithm to be applied:\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "def find_best_model_using_gridsearchcv(x,y):\n",
        "  algos={\n",
        "      'linear_regression':{\n",
        "          'model':LinearRegression(),\n",
        "          'params':{\n",
        "              'fit_intercept':[True,False]\n",
        "          }\n",
        "\n",
        "\n",
        "      },\n",
        "      'lasso':{\n",
        "          'model':Lasso(),\n",
        "          'params':{\n",
        "              'alpha':[1,2],\n",
        "              'selection':['random','cyclic']\n",
        "          }\n",
        "      },\n",
        "      'decision_tree':{\n",
        "          'model':DecisionTreeRegressor(),\n",
        "          'params':{\n",
        "              'criterion':['mse','friedman_mse'],\n",
        "              'splitter':['best','random']\n",
        "          }\n",
        "      }\n",
        "  }\n",
        "  scores=[]\n",
        "  cv=ShuffleSplit(n_splits=5,test_size=0.2,random_state=0)\n",
        "  for algo_name, config in algos.items():\n",
        "    gs=GridSearchCV(config['model'],config['params'],cv=cv,return_train_score=False)\n",
        "    gs.fit(x,y)\n",
        "    scores.append({\n",
        "        'model':algo_name,\n",
        "        'best_score':gs.best_score_,\n",
        "        'best_params':gs.best_params_\n",
        "    })\n",
        "\n",
        "  return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
        "\n",
        "print(find_best_model_using_gridsearchcv(x,y))\n",
        "x.columns\n",
        "#predicting price:\n",
        "def predict_price(loc,sqft,bath,bhk):\n",
        "  loc_index=np.where(x.columns==loc)[0][0]\n",
        "\n",
        "  Z=np.zeros(len(x.columns))\n",
        "  Z[0]=sqft\n",
        "  Z[1]=bath\n",
        "  Z[2]=bhk\n",
        "\n",
        "  if loc_index>=0:\n",
        "    Z[loc_index]=1\n",
        "\n",
        "  return lr_clf.predict([Z])[0]\n",
        "print(\"the predicted price is:\")\n",
        "print(predict_price('Yelahanka',1000,2,3))\n",
        "\n",
        "import pickle\n",
        "with open('banglore_prices_model.pickel','wb') as f:\n",
        "  pickle.dump(lr_clf,f)\n",
        "\n",
        "import json\n",
        "columns={\n",
        "    'data_columns':[col.lower() for col in x.columns]\n",
        "\n",
        "}\n",
        "with open(\"columns.json\",\"w\") as f:\n",
        "  f.write(json.dumps(columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9YZx5jK7rPC",
        "outputId": "43c65d87-2497-449c-8011-24a090107be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-3589fe674775>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data2['BHK']=data2['size'].apply(lambda x: int(x.split(' ')[0]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   location       size total_sqft  bath   price  BHK\n",
            "0  Electronic City Phase II      2 BHK       1056   2.0   39.07    2\n",
            "1          Chikka Tirupathi  4 Bedroom       2600   5.0  120.00    4\n",
            "2               Uttarahalli      3 BHK       1440   2.0   62.00    3\n",
            "3        Lingadheeranahalli      3 BHK       1521   3.0   95.00    3\n",
            "4                  Kothanur      2 BHK       1200   2.0   51.00    2\n",
            "(10241, 7)\n",
            "(7329, 7)\n",
            "(7251, 7)\n",
            "(7251, 245)\n",
            "0.8452277697874376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "10 fits failed out of a total of 20.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'squared_error', 'absolute_error', 'poisson', 'friedman_mse'}. Got 'mse' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.7127422  0.69266016]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               model  best_score  \\\n",
            "0  linear_regression    0.819001   \n",
            "1              lasso    0.687432   \n",
            "2      decision_tree    0.712742   \n",
            "\n",
            "                                         best_params  \n",
            "0                           {'fit_intercept': False}  \n",
            "1                {'alpha': 1, 'selection': 'random'}  \n",
            "2  {'criterion': 'friedman_mse', 'splitter': 'best'}  \n",
            "the predicted price is:\n",
            "44.828294911543374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JHbQ6r0Qzi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I_Oldws8Q0ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qc4MlhxyQ1C-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hg-W9e7QQwgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rB0TZ-ZtkQyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nfPEaao4kI_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUVrWxL3EJKm",
        "outputId": "aac57dcb-f14b-4299-fc1a-6bacac0ddffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-88-db38daabfe50>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data2['BHK'] = data2['size'].apply(lambda x: int(x.split(' ')[0]))\n",
            "<ipython-input-88-db38daabfe50>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data2['total_sqft'] = data2['total_sqft'].apply(converting_sqft_to_num)\n",
            "<ipython-input-88-db38daabfe50>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data2['Price_per_sqft'] = data2['price'] * 100000 / data2['total_sqft']\n",
            "<ipython-input-88-db38daabfe50>:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data2.location = data2.location.apply(lambda x: x.strip())\n",
            "<ipython-input-88-db38daabfe50>:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data2.location = data2.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9351389738256157\n",
            "               model  best_score  \\\n",
            "0  linear_regression    0.941271   \n",
            "1              lasso    0.924773   \n",
            "2      decision_tree    0.972326   \n",
            "\n",
            "                                         best_params  \n",
            "0                            {'fit_intercept': True}  \n",
            "1                {'alpha': 1, 'selection': 'cyclic'}  \n",
            "2  {'criterion': 'friedman_mse', 'splitter': 'best'}  \n",
            "-65.88305239879259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "10 fits failed out of a total of 20.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'squared_error', 'poisson', 'friedman_mse', 'absolute_error'}. Got 'mse' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.97232571 0.96876623]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}